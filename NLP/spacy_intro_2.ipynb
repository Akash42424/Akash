{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_intro_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruxvJFbkqbDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_AACzmBrgiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "48cc4b42-5f77-4c10-d4b3-2b0e4a604326"
      },
      "source": [
        "import spacy \n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "cat_hash=nlp.vocab.strings[\"cat\"]\n",
        "print(cat_hash)\n",
        "doc=nlp(\"i love cat\")\n",
        "cat=nlp.vocab.strings[cat_hash]\n",
        "print(cat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5439657043933447811\n",
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-nYfAqu1i2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "099c0c43-1042-4951-95c2-5151b4e99f49"
      },
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "word=[\"I\",\"likes\",\"it\",\"'\",\"s\",\"buddy\"]\n",
        "space=[True,True,False,False,True,False]\n",
        "\n",
        "doc=Doc(nlp.vocab,words=word,spaces=space)\n",
        "print(doc.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I likes it's buddy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pol_maebu1hQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c1dd5da5-184c-49f5-dd5b-bae1cfa0a899"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Import the Doc and Span classes\n",
        "from spacy.tokens import Doc, Span\n",
        "\n",
        "words = [\"I\", \"like\", \"David\", \"Bowie\"]\n",
        "spaces = [True, True, True, False]\n",
        "\n",
        "# Create a doc from the words and spaces\n",
        "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "print(doc.text)\n",
        "\n",
        "# Create a span for \"David Bowie\" from the doc and assign it the label(ent) \"PERSON\"\n",
        "span = Span(doc, 2, 4, label=\"PERSON\")\n",
        "print(span.text, span.label_)\n",
        "\n",
        "# Add the span to the doc's entities\n",
        "doc.ents = [span]\n",
        "\n",
        "# Print entities' text and labels\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I like David Bowie\n",
            "David Bowie PERSON\n",
            "[('David Bowie', 'PERSON')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD9XKqBau1fV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25b08723-98a2-44d1-af32-13a96dde44e8"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Berlin is a nice city\")\n",
        "\n",
        "# Iterate over the tokens\n",
        "for token in doc:\n",
        "    # Check if the current token is a proper noun\n",
        "    if token.pos_ == \"PROPN\":\n",
        "        # Check if the next token is a verb\n",
        "        if doc[token.i + 1].pos_ == \"VERB\":\n",
        "            print(\"Found proper noun before a verb:\", token.text)\n",
        "        else:\n",
        "          print(\"not found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTKfhwFqu1dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### inspecting word vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H0J6liQu1as",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "6a5835e9-b635-40f5-ebf7-f2807cb5937d"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load the en_core_web_md model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"Two bananas in pyjamas\")\n",
        "\n",
        "# Get the vector for the token \"bananas\"\n",
        "bananas_vector = doc[1].vector\n",
        "print(bananas_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.2009e-01 -3.0322e-02 -7.9859e-02 -4.6279e-01 -3.8600e-01  3.6962e-01\n",
            " -7.7178e-01 -1.1529e-01  3.3601e-02  5.6573e-01 -2.4001e-01  4.1833e-01\n",
            "  1.5049e-01  3.5621e-01 -2.1508e-01 -4.2743e-01  8.1400e-02  3.3916e-01\n",
            "  2.1637e-01  1.4792e-01  4.5811e-01  2.0966e-01 -3.5706e-01  2.3800e-01\n",
            "  2.7971e-02 -8.4538e-01  4.1917e-01 -3.9181e-01  4.0434e-04 -1.0662e+00\n",
            "  1.4591e-01  1.4643e-03  5.1277e-01  2.6072e-01  8.3785e-02  3.0340e-01\n",
            "  1.8579e-01  5.9999e-02 -4.0270e-01  5.0888e-01 -1.1358e-01 -2.8854e-01\n",
            " -2.7068e-01  1.1017e-02 -2.2217e-01  6.9076e-01  3.6459e-02  3.0394e-01\n",
            "  5.6989e-02  2.2733e-01 -9.9473e-02  1.5165e-01  1.3540e-01 -2.4965e-01\n",
            "  9.8078e-01 -8.0492e-01  1.9326e-01  3.1128e-01  5.5390e-02 -4.2423e-01\n",
            " -1.4082e-02  1.2708e-01  1.8868e-01  5.9777e-02 -2.2215e-01 -8.3950e-01\n",
            "  9.1987e-02  1.0180e-01 -3.1299e-01  5.5083e-01 -3.0717e-01  4.4201e-01\n",
            "  1.2666e-01  3.7643e-01  3.2333e-01  9.5673e-02  2.5083e-01 -6.4049e-02\n",
            "  4.2143e-01 -1.9375e-01  3.8026e-01  7.0883e-03 -2.0371e-01  1.5402e-01\n",
            " -3.7877e-03 -2.9396e-01  9.6518e-01  2.0068e-01 -5.6572e-01 -2.2581e-01\n",
            "  3.2251e-01 -3.4634e-01  2.7064e-01 -2.0687e-01 -4.7229e-01  3.1704e-01\n",
            " -3.4665e-01 -2.5188e-01 -1.1201e-01 -3.3937e-01  3.1518e-01 -3.2221e-01\n",
            " -2.4530e-01 -7.1571e-02 -4.3971e-01 -1.2070e+00  3.3365e-01 -5.8208e-02\n",
            "  8.0899e-01  4.2335e-01  3.8678e-01 -6.0797e-01 -7.3760e-01 -2.0547e-01\n",
            " -1.7499e-01 -3.7842e-03  2.1930e-01 -5.2486e-02  3.4869e-01  4.3852e-01\n",
            " -3.4471e-01  2.8910e-01  7.2554e-02 -4.8625e-01 -3.8390e-01 -4.4760e-01\n",
            "  4.3278e-01 -2.7128e-03 -9.0067e-01 -3.0819e-02 -3.8630e-01 -8.0798e-02\n",
            " -1.6243e-01  2.8830e-01 -2.6349e-01  1.7628e-01  3.5958e-01  5.7672e-01\n",
            " -5.4624e-01  3.8555e-02 -2.0182e+00  3.2916e-01  3.4672e-01  1.5398e-01\n",
            " -4.3446e-01 -4.1428e-02 -6.9588e-02  5.1513e-01 -1.3489e-01 -5.7239e-02\n",
            "  4.9241e-01  1.8643e-01  3.8596e-01 -3.7329e-02 -5.4216e-01 -1.8152e-01\n",
            "  4.3110e-01 -4.6967e-01  6.6801e-02  5.0323e-01 -2.4059e-01  3.6742e-01\n",
            "  2.9300e-01 -8.7883e-02 -4.7940e-01 -4.3431e-02 -2.6137e-01 -6.2658e-01\n",
            "  1.1446e-01  2.7682e-01  3.4800e-01  5.0018e-01  1.4269e-01 -3.3545e-01\n",
            " -3.9712e-01 -3.3121e-01 -3.4434e-01 -4.1627e-01 -3.5707e-03 -6.2350e-01\n",
            "  3.7794e-01 -1.6765e-01 -4.1954e-01 -3.3134e-01  3.1232e-01 -3.9494e-01\n",
            " -4.6921e-03 -4.8884e-01 -2.2059e-02 -2.6174e-01  1.7937e-01  3.6628e-01\n",
            "  5.8971e-02 -3.5991e-01 -4.4393e-01 -1.1890e-01  3.3487e-01  3.6505e-02\n",
            " -3.2788e-01  3.3425e-01 -5.6361e-01 -1.1190e-01  5.3770e-01  2.0311e-01\n",
            "  1.5110e-01  1.0623e-02  3.3401e-01  4.6084e-01  5.6293e-01 -7.5432e-02\n",
            "  5.4813e-01  1.9395e-01 -2.6265e-01 -3.1699e-01 -8.1778e-01  5.8169e-02\n",
            " -5.7866e-02 -1.1781e-01 -5.8742e-02 -1.4092e-01 -9.9394e-01 -9.4532e-02\n",
            "  2.3503e-01 -4.9027e-01  8.5832e-01  1.1540e-01 -1.5049e-01  1.9065e-01\n",
            " -2.6705e-01  2.5326e-01 -6.7579e-01 -1.0633e-02 -5.5158e-02 -3.1004e-01\n",
            " -5.8036e-02 -1.7200e-01  1.3298e-01 -3.2899e-01 -7.5481e-02  2.9425e-02\n",
            " -3.2949e-01 -1.8691e-01 -9.5323e-01 -3.5468e-01 -3.3162e-01  5.6441e-02\n",
            "  2.1790e-02  1.7182e-01 -4.4267e-01  6.9765e-01 -2.6876e-01  1.1659e-01\n",
            " -1.6584e-01  3.8296e-01  2.9109e-01  3.6318e-01  3.6961e-01  1.6305e-01\n",
            "  1.8152e-01  2.2453e-01  3.9866e-02 -3.7607e-02 -3.6089e-01  7.0818e-02\n",
            " -2.1509e-01  3.6551e-01 -5.1603e-01 -5.8102e-03 -4.8320e-01 -2.5068e-01\n",
            " -5.2062e-02 -2.0828e-01  2.9060e-01  2.2084e-02 -6.8123e-01  4.2063e-01\n",
            "  9.5973e-02  8.1720e-01 -1.5241e-01  6.2994e-01  2.6449e-01 -1.3516e-01\n",
            "  3.2450e-01  3.0503e-01  1.2357e-01  1.5107e-01  2.8327e-01 -3.3838e-01\n",
            "  4.6106e-02 -1.2361e-01  1.4516e-01 -2.7947e-02  2.6231e-02 -5.9591e-01\n",
            " -4.4183e-01  7.8440e-01 -3.4375e-02 -1.3928e+00  3.5248e-01  6.5220e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XyCtsAbu1Xl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c5061706-0b57-45da-f1e8-c6395c6cb0ca"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_md\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6aiG-Adu1UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### comaring semantic similarity\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip3KsVcFu1Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2270b5c4-1ba1-48e9-b173-7efe026d4a62"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "doc1 = nlp(\"It's a warm summer day\")\n",
        "doc2 = nlp(\"It's sunny outside\")\n",
        "doc3=nlp(\"i like to play cricket\")\n",
        "doc4=nlp(\"terrorist attack is very cruel act\")\n",
        "\n",
        "# Get the similarity of doc1 and doc2\n",
        "similarity = doc2.similarity(doc1)\n",
        "s=doc3.similarity(doc4)\n",
        "print(similarity,s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8789265574516525 0.5961483652720225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAbOfz8Guiyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c85030d5-104b-4f36-d9c7-6ca00f85de76"
      },
      "source": [
        "\n",
        "\n",
        "doc = nlp(\"TV and books\")\n",
        "token1, token2 = doc[0], doc[2]\n",
        "\n",
        "# Get the similarity of the tokens \"TV\" and \"books\"\n",
        "similarity = token1.similarity(token2)\n",
        "print(similarity)\n",
        "\n",
        "doc = nlp(\"This was a great restaurant. Afterwards, we went to a really nice bar.\")\n",
        "\n",
        "# Create spans for \"great restaurant\" and \"really nice bar\"\n",
        "span1 = doc[3:5]\n",
        "span2 = doc[12:15]\n",
        "\n",
        "# Get the similarity of the spans\n",
        "similarity = span1.similarity(span2)\n",
        "print(similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22325331\n",
            "0.75173926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3DIU9-uuixQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Combining models and rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0uMouMNuivv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3c2ab14a-33cb-43d4-afda-eab4f9b2d76c"
      },
      "source": [
        "###Recap: Rule-based Matching\n",
        "\n",
        "# Initialize with the shared vocab\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Patterns are lists of dictionaries describing the tokens\n",
        "pattern = [{\"LEMMA\": \"love\", \"POS\": \"VERB\"}]\n",
        "matcher.add(\"LOVE_CATS\", None, pattern)\n",
        "\n",
        "\"\"\"# Operators can specify how often a token should be matched\n",
        "pattern = [{\"TEXT\": \"very\", \"OP\": \"+\"}, {\"TEXT\": \"happy\"}]\n",
        "matcher.add(\"VERY_HAPPY\", None, pattern)\"\"\"\n",
        "\n",
        "# Calling matcher on doc returns list of (match_id, start, end) tuples\n",
        "doc = nlp(\"I love cats and I'm very very happy\")\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id,start,end in matches:\n",
        "    print(doc[start:end].text)\n",
        "\n",
        "\"\"\"####Adding statistical predictions\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add(\"DOG\", None, [{\"LOWER\": \"golden\"}, {\"LOWER\": \"retriever\"}])\n",
        "doc = nlp(\"I have a Golden Retriever\")\"\"\"\n",
        "\n",
        "\"\"\"for match_id, start, end in matcher(doc):\n",
        "    span = doc[start:end]\n",
        "    print(\"Matched span:\", span.text)\n",
        "    # Get the span's root token and root head token\n",
        "    print(\"Root token:\", span.root.text)\n",
        "    print(\"Root head token:\", span.root.head.text)\n",
        "    # Get the previous token and its POS tag\n",
        "    print(\"Previous token:\", doc[start - 1].text, doc[start - 1].pos_)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "love\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for match_id, start, end in matcher(doc):\\n    span = doc[start:end]\\n    print(\"Matched span:\", span.text)\\n    # Get the span\\'s root token and root head token\\n    print(\"Root token:\", span.root.text)\\n    print(\"Root head token:\", span.root.head.text)\\n    # Get the previous token and its POS tag\\n    print(\"Previous token:\", doc[start - 1].text, doc[start - 1].pos_)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy4LCePRuitx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50704d6e-2f89-47de-a105-eeadf66a1ed6"
      },
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "\n",
        "pattern = nlp(\"Golden Retriever\")\n",
        "matcher.add(\"DOG\", None, pattern)\n",
        "doc = nlp(\"I have a Golden Retriever\")\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matcher(doc):\n",
        "    # Get the matched span\n",
        "    span = doc[start:end]\n",
        "    print(\"Matched span:\", span.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matched span: Golden Retriever\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ns55Oikuirw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1536865e-e403-4512-b13e-672719304b3c"
      },
      "source": [
        "###Debugging  pattern\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\n",
        "    \"Twitch Prime, the perks program for Amazon Prime members offering free \"\n",
        "    \"loot, games and other benefits, is ditching one of its best features: \"\n",
        "    \"ad-free viewing. According to an email sent out to Amazon Prime members \"\n",
        "    \"today, ad-free viewing will no longer be included as a part of Twitch \"\n",
        "    \"Prime for new members, beginning on September 14. However, members with \"\n",
        "    \"existing annual subscriptions will be able to continue to enjoy ad-free \"\n",
        "    \"viewing until their subscription comes up for renewal. Those with \"\n",
        "    \"monthly subscriptions will have access to ad-free viewing until October 15.\"\n",
        ")\n",
        "\n",
        "# Create the match patterns\n",
        "#pattern1 = [{\"LOWER\": \"Amazon\"}, {\"IS_TITLE\": True, \"POS\": \"PROPN\"}]\n",
        "#pattern2 = [{\"LOWER\": \"ad-free\"}, {\"POS\": \"NOUN\"}]\n",
        "\n",
        "## Create the match patterns\n",
        "pattern1 = [{\"LOWER\": \"amazon\"}, {\"IS_TITLE\": True, \"POS\": \"PROPN\"}]\n",
        "pattern2 = [{\"LOWER\": \"ad\"}, {\"TEXT\": \"-\"}, {\"LOWER\": \"free\"}, {\"POS\": \"NOUN\"}]\n",
        "\n",
        "# Initialize the Matcher and add the patterns\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add(\"PATTERN1\", None, pattern1)\n",
        "matcher.add(\"PATTERN2\", None, pattern2)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matcher(doc):\n",
        "    # Print pattern string name and text of matched span\n",
        "    print(doc.vocab.strings[match_id], doc[start:end].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PATTERN1 Amazon Prime\n",
            "PATTERN2 ad-free viewing\n",
            "PATTERN1 Amazon Prime\n",
            "PATTERN2 ad-free viewing\n",
            "PATTERN2 ad-free viewing\n",
            "PATTERN2 ad-free viewing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ED389eNuiqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### effiecent phrase matching"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8OChGGOyDa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.tokens import Span\n",
        "import json\n",
        "\n",
        "with open(\"exercises/en/countries.json\") as f:\n",
        "    COUNTRIES = json.loads(f.read())\n",
        "with open(\"exercises/en/country_text.txt\") as f:\n",
        "    TEXT = f.read()\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "patterns = list(nlp.pipe(COUNTRIES))\n",
        "matcher.add(\"COUNTRY\", None, *patterns)\n",
        "\n",
        "# Create a doc and reset existing entities\n",
        "doc = nlp(TEXT)\n",
        "doc.ents = []\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matcher(doc):\n",
        "    # Create a Span with the label for \"GPE\"\n",
        "    span = ____(____, ____, ____, label=____)\n",
        "\n",
        "    # Overwrite the doc.ents and add the span\n",
        "    doc.ents = list(doc.ents) + [____]\n",
        "\n",
        "    # Get the span's root head token\n",
        "    span_root_head = ____.____.____\n",
        "    # Print the text of the span root's head token and the span text\n",
        "    print(span_root_head.____, \"-->\", span.text)\n",
        "\n",
        "# Print the entities in the document\n",
        "print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == \"GPE\"])\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4IcJ37-yDY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av5wurRAyDW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEvsfUIlyDU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRQIo2lzyDTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOZ_1lkqyDQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-VcQSJHyDMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en9CqL0ByDIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeYUg3n8yDFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDXp_GsXyDCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf63KQVwuijx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}