{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_intro_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6-iybr8FU75",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=11ZdYMTQXXgTTmAdJ4GFleDsU9McOU3tY)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APyv5wkeFzSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Name\t          Description\t                     Creates\n",
        "tagger\t     Part-of-speech tagger\t            Token.tag, Token.pos\n",
        "parser\t     Dependency parser\t                Token.dep, Token.head, Doc.sents, Doc.noun_chunks\n",
        "ner\t         Named entity recognizer\t          Doc.ents, Token.ent_iob, Token.ent_type\n",
        "textcat\t     Text classifier\tDoc.cats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgpdVHrvFzU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##inspecting the pipline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCeaBowdFzZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9879dc22-50c3-425c-c9d2-1b005560e80f"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load the en_core_web_sm model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Print the names of the pipeline components\n",
        "print(nlp.pipe_names)\n",
        "\n",
        "# Print the full pipeline of (name, component) tuples\n",
        "print(nlp.pipeline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger', 'parser', 'ner']\n",
            "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7fc6512ebc18>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7fc651145108>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7fc651145168>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vZc_kkVFznJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de53e612-9448-415b-a52e-70d1f46b04cf"
      },
      "source": [
        "## custom pipeline component\n",
        "\n",
        "# Create the nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a custom component\n",
        "def custom_component(doc):\n",
        "    # Print the doc's length\n",
        "    print(\"Doc length:\", len(doc))\n",
        "    # Return the doc object\n",
        "    return doc\n",
        "\n",
        "# Add the component first in the pipeline\n",
        "nlp.add_pipe(custom_component, first=True)\n",
        "\n",
        "# Print the pipeline component names\n",
        "print(\"Pipeline:\", nlp.pipe_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline: ['custom_component', 'tagger', 'parser', 'ner']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfI7G3t1FztR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b13662e5-5c2e-4b44-9d92-8bc531893bc7"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Define the custom component\n",
        "def length_component(doc):\n",
        "    # Get the doc's length\n",
        "    doc_length = len(doc)\n",
        "    print(f\"This document is {doc_length} tokens long.\")\n",
        "    # Return the doc\n",
        "    return doc\n",
        "\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add the component first in the pipeline and print the pipe names\n",
        "nlp.add_pipe(length_component, first=True)\n",
        "print(nlp.pipe_names)\n",
        "doc = nlp(\"This is a sentence.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['length_component', 'tagger', 'parser', 'ner']\n",
            "This document is 5 tokens long.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgiCCJWdFzy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "56d9efa3-874c-4149-e4f7-060f1fa93329"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "animals = [\"Golden Retriever\", \"cat\", \"turtle\", \"Rattus norvegicus\"]\n",
        "animal_patterns = list(nlp.pipe(animals))\n",
        "print(\"animal_patterns:\", animal_patterns)\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "matcher.add(\"ANIMAL\", None, *animal_patterns)\n",
        "\n",
        "# Define the custom component\n",
        "def animal_component(doc):\n",
        "    # Apply the matcher to the doc\n",
        "    matches = matcher(doc)\n",
        "    # Create a Span for each match and assign the label \"ANIMAL\"\n",
        "    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n",
        "    # Overwrite the doc.ents with the matched spans\n",
        "    doc.ents = spans\n",
        "    return doc\n",
        "\n",
        "\n",
        "# Add the component to the pipeline after the \"ner\" component\n",
        "nlp.add_pipe(animal_component, after=\"ner\")\n",
        "print(nlp.pipe_names)\n",
        "\n",
        "# Process the text and print the text and label for the doc.ents\n",
        "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "animal_patterns: [Golden Retriever, cat, turtle, Rattus norvegicus]\n",
            "['tagger', 'parser', 'ner', 'animal_component']\n",
            "[('cat', 'ANIMAL'), ('Golden Retriever', 'ANIMAL')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp_GAcXDFzv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "638c04bd-8676-47dc-8f83-e0c9fba25734"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Token\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Register the Token extension attribute \"is_country\" with the default value False\n",
        "Token.set_extension(\"is_country\", default=False)\n",
        "\n",
        "# Process the text and set the is_country attribute to True for the token \"Spain\"\n",
        "doc = nlp(\"I live in Spain.\")\n",
        "doc[3]._.is_country = True\n",
        "\n",
        "# Print the token text and the is_country attribute for all tokens\n",
        "print([(token.text, token._.is_country) for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I', False), ('live', False), ('in', False), ('Spain', True), ('.', False)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2yZXA6FFzre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "8f1437dd-bba2-46f6-d3cd-5156b06b6b43"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Token\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Define the getter function that takes a token and returns its reversed text\n",
        "def get_reversed(token):\n",
        "    return token.text[::-1]\n",
        "\n",
        "\n",
        "# Register the Token property extension \"reversed\" with the getter get_reversed\n",
        "Token.set_extension(\"reversed\", getter=get_reversed)\n",
        "\n",
        "# Process the text and print the reversed attribute for each token\n",
        "doc = nlp(\"All generalizations are false, including this one.\")\n",
        "for token in doc:\n",
        "    print(\"reversed:\", token._.reversed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reversed: llA\n",
            "reversed: snoitazilareneg\n",
            "reversed: era\n",
            "reversed: eslaf\n",
            "reversed: ,\n",
            "reversed: gnidulcni\n",
            "reversed: siht\n",
            "reversed: eno\n",
            "reversed: .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLjm8bZFzla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ac4524c-c4f0-4314-e764-c24838d06c02"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Define the getter function\n",
        "def get_has_number(doc):\n",
        "    # Return if any of the tokens in the doc return True for token.like_num\n",
        "    return any(token.like_num for token in doc)\n",
        "\n",
        "\n",
        "# Register the Doc property extension \"has_number\" with the getter get_has_number\n",
        "Doc.set_extension(\"has_number\", getter=get_has_number)\n",
        "\n",
        "# Process the text and check the custom has_number attribute\n",
        "doc = nlp(\"The museum closed for five years in 2012.\")\n",
        "print(\"has_number:\", doc._.has_number)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "has_number: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5zcqzN0Fzja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a7dca7a-3dc9-48eb-feba-afce8b518c32"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Define the method\n",
        "def to_html(span, tag):\n",
        "    # Wrap the span text in a HTML tag and return it\n",
        "    return f\"<{tag}>{span.text}</{tag}>\"\n",
        "\n",
        "\n",
        "# Register the Span method extension \"to_html\" with the method to_html\n",
        "Span.set_extension(\"to_html\", method=to_html)\n",
        "\n",
        "# Process the text and call the to_html method on the span with the tag name \"strong\"\n",
        "doc = nlp(\"Hello world, this is a sentence.\")\n",
        "span = doc[0:2]\n",
        "print(span._.to_html(\"strong\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<strong>Hello world</strong>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r_Quf0JFzhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7ef0551e-0cf9-4535-d638-c212bc68c702"
      },
      "source": [
        "##entities and extension\n",
        "import spacy\n",
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def get_wikipedia_url(span):\n",
        "    # Get a Wikipedia URL if the span has one of the labels\n",
        "    if span.label_ in (\"PERSON\", \"ORG\", \"GPE\", \"LOCATION\"):\n",
        "        entity_text = span.text.replace(\" \", \"_\")\n",
        "        return \"https://en.wikipedia.org/w/index.php?search=\" + entity_text\n",
        "\n",
        "\n",
        "# Set the Span extension wikipedia_url using get getter get_wikipedia_url\n",
        "Span.set_extension(\"wikipedia_url\", getter=get_wikipedia_url)\n",
        "\n",
        "doc = nlp(\n",
        "    \"In over fifty years from his very first recordings right through to his \"\n",
        "    \"last album, David Bowie was at the vanguard of contemporary culture.\"\n",
        ")\n",
        "for ent in doc.ents:\n",
        "    # Print the text and Wikipedia URL of the entity\n",
        "    print(ent.text, ent._.wikipedia_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fifty years None\n",
            "David Bowie https://en.wikipedia.org/w/index.php?search=David_Bowie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDLumuweFzeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "f1c6b63e-afd3-4161-d8fc-50bd17f5bb2a"
      },
      "source": [
        "import json\n",
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Span\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "with open(\"exercises/en/countries.json\") as f:\n",
        "    COUNTRIES = json.loads(f.read())\n",
        "\n",
        "with open(\"exercises/en/capitals.json\") as f:\n",
        "    CAPITALS = json.loads(f.read())\n",
        "\n",
        "nlp = English()\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "matcher.add(\"COUNTRY\", None, *list(nlp.pipe(COUNTRIES)))\n",
        "\n",
        "\n",
        "def countries_component(doc):\n",
        "    # Create an entity Span with the label \"GPE\" for all matches\n",
        "    matches = matcher(doc)\n",
        "    doc.ents = [Span(doc, start, end, label=\"GPE\") for match_id, start, end in matches]\n",
        "    return doc\n",
        "\n",
        "\n",
        "# Add the component to the pipeline\n",
        "nlp.add_pipe(countries_component)\n",
        "print(nlp.pipe_names)\n",
        "\n",
        "# Getter that looks up the span text in the dictionary of country capitals\n",
        "get_capital = lambda span: CAPITALS.get(span.text)\n",
        "\n",
        "# Register the Span extension attribute \"capital\" with the getter get_capital\n",
        "Span.set_extension(\"capital\", getter=get_capital)\n",
        "\n",
        "# Process the text and print the entity text, label and capital attributes\n",
        "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n",
        "print([(ent.text, ent.label_, ent._.capital) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3c71853b0e9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhraseMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exercises/en/countries.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mCOUNTRIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exercises/en/countries.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xjexk2nFzcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### processing stream\n",
        "import json\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "with open(\"exercises/en/tweets.json\") as f:\n",
        "    TEXTS = json.loads(f.read())\n",
        "\n",
        "# Process the texts and print the adjectives\n",
        "for text in TEXTS:\n",
        "    doc = nlp(text)\n",
        "    print([token.text for token in doc if token.pos_ == \"ADJ\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dleG9KwjFzX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "people = [\"David Bowie\", \"Angela Merkel\", \"Lady Gaga\"]\n",
        "\n",
        "# Create a list of patterns for the PhraseMatcher\n",
        "patterns = [nlp(person) for person in people]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgRbTAnGQs93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "0cb454ab-6dd6-4b50-a3e0-8636aafaf148"
      },
      "source": [
        "###selective processing\n",
        "import spacy\n",
        "​\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = (\n",
        "    \"Chick-fil-A is an American fast food restaurant chain headquartered in \"\n",
        "    \"the city of College Park, Georgia, specializing in chicken sandwiches.\"\n",
        ")\n",
        "​\n",
        "# Only tokenize the text\n",
        "doc = nlp(text)\n",
        "print([token.text for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-c340ee36220f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ​\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb48msUYQtPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}